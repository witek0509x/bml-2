#!/bin/bash
#SBATCH --job-name=multi_node
#SBATCH --output=log_multi_node_%j.out
#SBATCH --error=log_multi_node%j.err
#SBATCH --partition=plgrid-gpu-a100
#SBATCH --account=plgllmparamgr-gpu-a100
#SBATCH --nodes=2
#SBATCH --gres=gpu:1
#SBATCH --cpus-per-gpu=4
#SBATCH --time=0-00:05:00
#SBATCH --mem=16G

nodes=( $( scontrol show hostnames $SLURM_JOB_NODELIST ) )
nodes_array=($nodes)
head_node=${nodes_array[0]}
head_node_ip=$(srun --nodes=1 --ntasks=1 -w "$head_node" hostname --ip-address)

echo Node IP: $head_node_ip
echo Nodes: $nodes_array $head_node
export LOGLEVEL=INFO

source $HOME/venv/bin/activate
source $SCRATCH/bml-2/.env

torchrun \
  --nnodes 2 \
  --nproc_per_node 1 \
  --rdzv_id $RANDOM \
  --rdzv_backend c10d \
  --rdzv_endpoint $head_node_ip:29500 \
  ./main.py \
  --n_training_steps 2000 \
  --batch_size 256 \
  --n_layers 4 \
  --dmodel 256 \
  --n_heads 4